{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwNtF0AxozV770qp3bxU8i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fletchdr7/cadet_data_solution/blob/main/cadet_data_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################\n",
        "# 1) INSTALL & IMPORT LIBRARIES\n",
        "##########################################\n",
        "\n",
        "!pip install striprtf thefuzz\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sqlite3\n",
        "from thefuzz import process\n",
        "from striprtf.striprtf import rtf_to_text\n",
        "from io import StringIO\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "print(\"Libraries installed and imported.\")\n",
        "\n",
        "##########################################\n",
        "# 2) UPLOAD & PARSE THE RTF FILE\n",
        "##########################################\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Please upload your .rtf file (e.g., W_DFAS_257.rtf).\")\n",
        "uploaded_rtf = files.upload()\n",
        "rtf_filename = list(uploaded_rtf.keys())[0]\n",
        "print(f\"RTF file uploaded as: {rtf_filename}\")\n",
        "\n",
        "# Decode the raw bytes\n",
        "rtf_bytes = uploaded_rtf[rtf_filename]\n",
        "rtf_text = rtf_bytes.decode('utf-8', errors='ignore')\n",
        "\n",
        "# Convert RTF to plain text\n",
        "plain_text = rtf_to_text(rtf_text)\n",
        "print(\"\\nPreview of RTF plain text (first 500 characters):\")\n",
        "print(plain_text[:500])\n",
        "\n",
        "##########################################\n",
        "# 3) PARSE THE RTF TABLE (PIPE-DELIMITED)\n",
        "##########################################\n",
        "\n",
        "# We'll assume the first table is pipe-delimited (e.g. 'SSN|NAME|PGM CD|...')\n",
        "# We'll collect lines until we hit a blank line\n",
        "\n",
        "lines = plain_text.splitlines()\n",
        "table_lines = []\n",
        "found_header = False\n",
        "\n",
        "for line in lines:\n",
        "    if line.startswith(\"SSN|\"):  # or whatever your header starts with\n",
        "        found_header = True\n",
        "\n",
        "    if found_header:\n",
        "        if line.strip() == \"\":\n",
        "            # blank line => end of table\n",
        "            break\n",
        "        table_lines.append(line)\n",
        "\n",
        "# Join them into a single string for pandas\n",
        "table_str = \"\\n\".join(table_lines)\n",
        "\n",
        "# Read into a DataFrame\n",
        "df_rtf = pd.read_csv(StringIO(table_str), sep=\"|\")\n",
        "\n",
        "print(\"\\nInitial df_rtf from RTF table:\")\n",
        "display(df_rtf.head())\n",
        "\n",
        "# Remove any unnamed columns (extra columns from trailing separators)\n",
        "unnamed_cols = [c for c in df_rtf.columns if \"Unnamed\" in c]\n",
        "if unnamed_cols:\n",
        "    df_rtf.drop(columns=unnamed_cols, inplace=True)\n",
        "    print(f\"Dropped unnamed columns: {unnamed_cols}\")\n",
        "\n",
        "##########################################\n",
        "# 4) CONVERT NUMERIC COLUMNS IF NEEDED\n",
        "##########################################\n",
        "\n",
        "numeric_cols = [\n",
        "    \"SUBSIS    PAID\",\n",
        "    \"BOOKS & FEES\",\n",
        "    \"TRAINING PAID\",\n",
        "    \"BONUS PAID\",\n",
        "    \"COMM PAID\",\n",
        "    \"TRN DAY\",\n",
        "    \"COLLECTION\",\n",
        "    \"NET PAY\",\n",
        "    \"CUM SUBSIS\",\n",
        "    \"CUM SUB DAY\",\n",
        "]\n",
        "for col in numeric_cols:\n",
        "    if col in df_rtf.columns:\n",
        "        df_rtf[col] = pd.to_numeric(df_rtf[col], errors=\"coerce\")\n",
        "\n",
        "# If there's a date column like 'ROTC GRAD DATE', we can convert it as well:\n",
        "if \"ROTC GRAD DATE\" in df_rtf.columns:\n",
        "    df_rtf[\"ROTC GRAD DATE\"] = pd.to_datetime(df_rtf[\"ROTC GRAD DATE\"], format=\"%Y%m%d\", errors=\"coerce\")\n",
        "\n",
        "print(\"\\nAfter numeric/date conversion:\")\n",
        "df_rtf.info()\n",
        "\n",
        "##########################################\n",
        "# 5) UPLOAD & CLEAN THE CSV\n",
        "##########################################\n",
        "\n",
        "print(\"\\nUpload your SMR_AS_FAVORITE.csv file:\")\n",
        "uploaded_csv = files.upload()\n",
        "csv_filename = list(uploaded_csv.keys())[0]\n",
        "print(f\"CSV file uploaded as: {csv_filename}\")\n",
        "\n",
        "df_csv = pd.read_csv(csv_filename)\n",
        "print(\"\\nOriginal df_csv columns:\")\n",
        "print(df_csv.columns.tolist())\n",
        "\n",
        "# If the CSV uses 'Name' instead of 'NAME', rename for consistency\n",
        "if \"Name\" in df_csv.columns:\n",
        "    df_csv.rename(columns={\"Name\": \"NAME\"}, inplace=True)\n",
        "\n",
        "print(\"Updated df_csv columns:\")\n",
        "print(df_csv.columns.tolist())\n",
        "display(df_csv.head())\n",
        "\n",
        "##########################################\n",
        "# 6) MAP THE RTF PGM CD -> AS YEAR\n",
        "##########################################\n",
        "\n",
        "# The RTF has a 'PGM CD' column that we map to AS years (e.g. SC01 -> AS100, etc.)\n",
        "pgm_to_as_year = {\n",
        "    \"SC01\": \"AS100\",\n",
        "    \"SC02\": \"AS200\",\n",
        "    \"NS03\": \"AS300\",\n",
        "    \"NS04\": \"AS400\",\n",
        "}\n",
        "\n",
        "if \"PGM CD\" in df_rtf.columns:\n",
        "    df_rtf[\"as_label_rtf\"] = df_rtf[\"PGM CD\"].map(pgm_to_as_year)\n",
        "else:\n",
        "    print(\"WARNING: 'PGM CD' not in df_rtf columns. Skipping as_label_rtf.\")\n",
        "\n",
        "##########################################\n",
        "# 7) USE CSV'S ALREADY EXISTING 'AS Year'\n",
        "##########################################\n",
        "\n",
        "# In your CSV, you have a column 'AS Year' that might say AS100, AS200, etc.\n",
        "# We'll rename that to 'as_label_csv' so it lines up with the RTF's concept:\n",
        "if \"AS Year\" in df_csv.columns:\n",
        "    df_csv.rename(columns={\"AS Year\": \"as_label_csv\"}, inplace=True)\n",
        "else:\n",
        "    print(\"WARNING: No 'AS Year' column in df_csv. We'll skip as_label_csv.\")\n",
        "\n",
        "##########################################\n",
        "# 8) CREATE A COMBINED KEY (NAME + AS YEAR) FOR FUZZY MATCH\n",
        "##########################################\n",
        "\n",
        "def build_fuzzy_key(name, label):\n",
        "    if pd.isna(name):\n",
        "        name = \"\"\n",
        "    if pd.isna(label):\n",
        "        label = \"\"\n",
        "    return f\"{name.strip().upper()}-{label.strip().upper()}\"\n",
        "\n",
        "# Build fuzzy_key_rtf\n",
        "if \"NAME\" in df_rtf.columns and \"as_label_rtf\" in df_rtf.columns:\n",
        "    df_rtf[\"fuzzy_key_rtf\"] = df_rtf.apply(\n",
        "        lambda row: build_fuzzy_key(row[\"NAME\"], row[\"as_label_rtf\"]), axis=1\n",
        "    )\n",
        "else:\n",
        "    print(\"Skipping fuzzy_key_rtf creation (missing columns).\")\n",
        "\n",
        "# Build fuzzy_key_csv\n",
        "# We'll assume CSV also has 'NAME' and we just renamed 'AS Year' to 'as_label_csv'\n",
        "if \"NAME\" in df_csv.columns and \"as_label_csv\" in df_csv.columns:\n",
        "    df_csv[\"fuzzy_key_csv\"] = df_csv.apply(\n",
        "        lambda row: build_fuzzy_key(row[\"NAME\"], row[\"as_label_csv\"]), axis=1\n",
        "    )\n",
        "else:\n",
        "    print(\"Skipping fuzzy_key_csv creation (missing columns).\")\n",
        "\n",
        "print(\"\\nPreview RTF keys:\")\n",
        "display(df_rtf[[\"NAME\", \"PGM CD\", \"as_label_rtf\", \"fuzzy_key_rtf\"]].head(10))\n",
        "\n",
        "print(\"\\nPreview CSV keys:\")\n",
        "if \"fuzzy_key_csv\" in df_csv.columns:\n",
        "    display(df_csv[[\"NAME\", \"as_label_csv\", \"fuzzy_key_csv\"]].head(10))\n",
        "else:\n",
        "    display(df_csv.head(10))\n",
        "\n",
        "##########################################\n",
        "# 9) FUZZY MATCH df_rtf KEYS AGAINST df_csv KEYS\n",
        "##########################################\n",
        "\n",
        "if \"fuzzy_key_rtf\" in df_rtf.columns and \"fuzzy_key_csv\" in df_csv.columns:\n",
        "    possible_keys = df_csv[\"fuzzy_key_csv\"].tolist()\n",
        "else:\n",
        "    print(\"No fuzzy_key columns in RTF or CSV. Fuzzy match cannot proceed.\")\n",
        "    possible_keys = []\n",
        "\n",
        "best_matches = []\n",
        "match_scores = []\n",
        "\n",
        "for combined_key in df_rtf.get(\"fuzzy_key_rtf\", []):\n",
        "    result = process.extractOne(combined_key, possible_keys)\n",
        "    if result is None:\n",
        "        best_matches.append(None)\n",
        "        match_scores.append(0)\n",
        "    else:\n",
        "        # thefuzz.process.extractOne usually returns (best_string, score)\n",
        "        best_str, best_score = result\n",
        "        best_matches.append(best_str)\n",
        "        match_scores.append(best_score)\n",
        "\n",
        "df_rtf[\"BEST_MATCH\"] = best_matches\n",
        "df_rtf[\"MATCH_SCORE\"] = match_scores\n",
        "\n",
        "print(\"\\nFuzzy matching complete. Check a few rows:\")\n",
        "display(df_rtf[[\"NAME\", \"PGM CD\", \"as_label_rtf\", \"fuzzy_key_rtf\", \"BEST_MATCH\", \"MATCH_SCORE\"]].head(20))\n",
        "\n",
        "##########################################\n",
        "# 10) MERGE THE TWO DATAFRAMES ON THE FUZZY KEY\n",
        "##########################################\n",
        "\n",
        "df_merged = pd.merge(\n",
        "    df_rtf,\n",
        "    df_csv,\n",
        "    how=\"left\",\n",
        "    left_on=\"BEST_MATCH\",    # best fuzzy match from df_rtf\n",
        "    right_on=\"fuzzy_key_csv\" # actual fuzzy key in df_csv\n",
        ")\n",
        "\n",
        "print(\"\\nMerged DataFrame shape:\", df_merged.shape)\n",
        "print(\"Merged DataFrame columns:\")\n",
        "print(df_merged.columns.tolist())\n",
        "display(df_merged.head(20))\n",
        "\n",
        "##########################################\n",
        "# 11) OPTIONAL: STORE IN SQLITE\n",
        "##########################################\n",
        "\n",
        "db_name = \"cadet_data.db\"\n",
        "if Path(db_name).exists():\n",
        "    os.remove(db_name)  # remove old copy if desired\n",
        "\n",
        "conn = sqlite3.connect(db_name)\n",
        "df_merged.to_sql(\"cadet_info\", conn, if_exists=\"replace\", index=False)\n",
        "\n",
        "print(f\"\\nData written to SQLite DB '{db_name}' in table 'cadet_info'.\")\n",
        "conn.close()\n",
        "\n",
        "print(\"\\n--- DONE! ---\")\n"
      ],
      "metadata": {
        "id": "mNJP4Q5XJ8oE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}